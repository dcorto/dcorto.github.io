---
title: '¿Tienen los LLMs una inteligencia real o es solo una ilusión?'
slug: 'tienen-los-llms-una-inteligencia-real-o-es-solo-una-ilusion'
date: 2025-06-22T11:00:00+02:00
draft: false
type: 'blog'
tags: 
    - ia
    - tecnología  
    - innovación
---

![](/images/blog/20250622-tienen-los-llms-una-inteligencia-real-o-es-solo-una-ilusion.jpeg "¿Tienen los LLMs una inteligencia real o es solo una ilusión?")

¿Tienen los LLMs una inteligencia real o es solo una ilusión? El reciente paper publicado por seis científicos de Apple, 
titulado "The illusion of thinking", en https://machinelearning.apple.com/research/illusion-of-thinking, 
ha generado un debate muy significativo en la comunidad tecnológica. Este paper cuestiona la capacidad de los 
modelos de lenguaje actuales para realizar razonamientos complejos y sugiere que, a pesar de aparentar procesos 
de “deep thinking” estos modelos “fallan” al enfrentarse a problemas de mayor complejidad. Usando puzzles matemáticos 
como la torre de Hanoi o el problema de cruzar el río, los investigadores han observado que la precisión de los modelos 
baja a medida que los problemas se complican.

Debemos aclarar que el concepto de “inteligencia” o “pensamiento” en inteligencia artificial no está muy claro. 
Intuitivamente, asociamos la inteligencia con la capacidad de razonar, entender y adaptarse a nuevas situaciones. 
Sin embargo, los modelos de lenguaje actuales, aunque impresionantes en su capacidad para generar texto coherente, 
no tienen una comprensión real del contenido que producen. Su funcionamiento se basa en la predicción estadística de 
palabras, sin conocer del significado subyacente.

En términos de capacidad de procesar volumen de datos, sin duda, los modelos de IA actuales superan a los humanos. 
Pero cuando hay que aplicar ese conocimiento con criterio, sentido e intencionalidad, la respuesta es más compleja. 
Los modelos no “piensan”, analizan patrones estadísticos en la cantidad enorme de datos que son capaces de manejar.

La diferencia con un humano no está solo en la cantidad de conocimiento disponible, sino en la capacidad de ponerlo 
en contexto, valorarlo críticamente y aplicar sentido común. Un agente capaz de analizar textos científicos no 
se convierte automáticamente en un experto: carece de intencionalidad, de experiencia vivida y de juicio propio.

A pesar de las limitaciones, la IA sigue avanzando en su desarrollo de emular a los humanos, los avances en inteligencia 
artificial son notables y están teniendo una capacidad de transformar nuestra sociedad con una velocidad vertiginosa, pero 
no debemos olvidar de que, por ahora, no son capaces de razonar ni aplicar sentido común o emocional. Por ahora.

Este artículo se publicó primero en [LinkedIn](https://www.linkedin.com/posts/davidcortocamacho_inteligenciaartificial-ia-llm-activity-7342476459782955008-Ql6J)
